# Second Homework

## This homework is mainly focused on the following topics:

* **`Generalize Linear Regression`**

* **`Bayesian Decision Theory`**

* **`Bayesian Classifier`**

* **`Optimal Classifier`**

* **`Minimum Risk Classification`**

* **`Neyman-Pearson Criterion`**

* **`Discriminant Functions`**

* **`Discriminability`** : **`ROC`** curve.


## Codes and Report

* In the seventh problem, I have implemented **Generalized Linear Regression** on [**nyc_cyclist_counts**](https://github.com/ARokni/Machine-Learning/blob/main/Homework/2/Problem%207/nyc_cyclist_counts.csv) in order to forcast the number of cyclists depending on daily temperature and humidity. The codes are provided in [P_7](https://github.com/ARokni/Machine-Learning/blob/main/Homework/2/Problem%207/P7.py).

* In the eightth problem, I have implemented a **python** code utilizing **`numpy`** on **`Iris Dataset`** in order to:

    - **`Preprocess`** the data(**`Normalization`**, **`Z-Score`**).
    - Slecet the **best pair of features** for **classification**.
    - Provide a classifier with **`Nearest Centroid`** algorithm.
    - Evaluate the model performance utilizing **`Confusion Matrix`**, **`F1-Score`**, and **`Accuracy`**.

The codes are provided in [P_8](https://github.com/ARokni/Machine-Learning/blob/main/Homework/2/Problem%208/P8.py).

* In the nineth problem, I have implemented **`Naive-Bayes calssifier`** and **`Optimal-Bayes classifier`** utilizing **numpy** on **`Tiny Mnist`** and **`Noisy Moons`**. The codes are provided in [P_9_NaiveBayes](https://github.com/ARokni/Machine-Learning/blob/main/Homework/2/Problem%209/P_9_NaiveBayes.py) and [P_9_OptimalBayes](https://github.com/ARokni/Machine-Learning/blob/main/Homework/2/Problem%209/P_9_OptimalBayes.py).

* In the tenth problem , I have implemented **`Logistic Regression`** utilizing **numpy** on [**random_dataset**](https://github.com/ARokni/Machine-Learning/blob/main/Homework/2/Problem%2010/random_dataset.csv). Since there are more than two classes in the dataset, I employed **`One Vs Rest`** method to implement my classifier. The codes are provided in [P_10](https://github.com/ARokni/Machine-Learning/blob/main/Homework/2/Problem%2010/P10.py).

* In the eleventh problem, I have implemented **`Logistic Regression`** utilizing python packages on [**quality_test**](https://github.com/ARokni/Machine-Learning/blob/main/Homework/2/Problem%2011/quality_test.csv) dataset. Sine the data is not **`Linearly Seperable`**, I had implemented a trnsformation in order to transfomr the data to a higher-dimensional space. In the new space, the transformed data can be easily seperated utilizing **Logistic Regression**. The codes are provided in [P_11](https://github.com/ARokni/Machine-Learning/blob/main/Homework/2/Problem%2011/P11.py)

* The assignment and my report are available in [Files](https://github.com/ARokni/Machine-Learning/tree/main/Homework/1/Files).